{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e64be6c-ecac-4a12-841a-518e821b636c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rewriting CSVs: 100%|███████████████████████| 928/928 [11:56:39<00:00, 46.34s/it]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Rewrite all existing CSVs:\n",
    "roi_polygon_wkt -> c1_lon,c1_lat,...,c4_lon,c4_lat\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ====== CONFIG ======\n",
    "output_root = \"/mnt/cephfs-mount/chenchen/CygnssDataCsv\"  # root of CSVs\n",
    "OVERWRITE = True   # set False if you want *_compact.csv copies\n",
    "\n",
    "PAIR_RE = re.compile(r\"(-?\\d+(?:\\.\\d+)?)\\s+(-?\\d+(?:\\.\\d+)?)\")\n",
    "\n",
    "def parse_wkt_corners(wkt):\n",
    "    \"\"\"Return 8 numbers from roi_polygon_wkt (NaNs if invalid).\"\"\"\n",
    "    if not isinstance(wkt, str) or not wkt.strip():\n",
    "        return (math.nan,)*8\n",
    "    pairs = [(float(x), float(y)) for x,y in PAIR_RE.findall(wkt)]\n",
    "    if len(pairs) >= 5 and pairs[0] == pairs[-1]:\n",
    "        pairs = pairs[:-1]\n",
    "    if len(pairs) < 4:\n",
    "        return (math.nan,)*8\n",
    "    c1,c2,c3,c4 = pairs[:4]\n",
    "    return (c1[0],c1[1],c2[0],c2[1],c3[0],c3[1],c4[0],c4[1])\n",
    "\n",
    "def process_csv(path):\n",
    "    df = pd.read_csv(path)\n",
    "    if \"roi_polygon_wkt\" not in df.columns:\n",
    "        return\n",
    "    corners = df[\"roi_polygon_wkt\"].apply(parse_wkt_corners)\n",
    "    corners_df = pd.DataFrame(corners.tolist(),\n",
    "        columns=[\"c1_lon\",\"c1_lat\",\"c2_lon\",\"c2_lat\",\"c3_lon\",\"c3_lat\",\"c4_lon\",\"c4_lat\"])\n",
    "    df = pd.concat([df.drop(columns=[\"roi_polygon_wkt\"]), corners_df], axis=1)\n",
    "\n",
    "    if OVERWRITE:\n",
    "        out_path = path\n",
    "    else:\n",
    "        base,ext = os.path.splitext(path)\n",
    "        out_path = base + \"_compact\" + ext\n",
    "    df.to_csv(out_path, index=False)\n",
    "\n",
    "def main():\n",
    "    csv_files = []\n",
    "    for dirpath, _, files in os.walk(output_root):\n",
    "        for f in files:\n",
    "            if f.lower().endswith(\".csv\"):\n",
    "                csv_files.append(os.path.join(dirpath, f))\n",
    "    if not csv_files:\n",
    "        print(\"No CSVs found under\", output_root)\n",
    "        return\n",
    "    for f in tqdm(csv_files, desc=\"Rewriting CSVs\"):\n",
    "        try:\n",
    "            process_csv(f)\n",
    "        except Exception as e:\n",
    "            print(\"[WARN]\", f, e)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
