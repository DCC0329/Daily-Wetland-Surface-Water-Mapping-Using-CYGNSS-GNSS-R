{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6e95d67-3772-4dd7-85e2-c46517e1182a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*** Earth Engine *** Share your feedback by taking our Annual Developer Satisfaction Survey: https://google.qualtrics.com/jfe/form/SV_7TDKVSyKvBdmMqW?ref=4i2o6\n",
      "                                                                     "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 305\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[38;5;66;03m# Optional: write an empty CSV with only headers if read succeeded earlier.\u001b[39;00m\n\u001b[1;32m    302\u001b[0m             \u001b[38;5;66;03m# Here we just continue.\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 305\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 298\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 298\u001b[0m     \u001b[43mprocess_one_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    300\u001b[0m     tqdm\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to process \u001b[39m\u001b[38;5;132;01m{\u001b[39;00min_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 258\u001b[0m, in \u001b[0;36mprocess_one_csv\u001b[0;34m(input_csv_path, output_csv_path)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    256\u001b[0m region \u001b[38;5;241m=\u001b[39m ee\u001b[38;5;241m.\u001b[39mGeometry\u001b[38;5;241m.\u001b[39mPolygon([region_coords], \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 258\u001b[0m frac, method, thr \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_water_fraction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate_ee\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m frac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(frac):\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m PRINT_PER_ROW:\n",
      "Cell \u001b[0;32mIn[2], line 178\u001b[0m, in \u001b[0;36mcalculate_water_fraction\u001b[0;34m(region, date_ee)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _SLOPE_MASK\n\u001b[1;32m    176\u001b[0m date_str \u001b[38;5;241m=\u001b[39m ee\u001b[38;5;241m.\u001b[39mDate(date_ee)\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYYYY-MM-dd\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mgetInfo()\n\u001b[0;32m--> 178\u001b[0m img_s1 \u001b[38;5;241m=\u001b[39m \u001b[43m_load_s1_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m img_s1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 76\u001b[0m, in \u001b[0;36m_load_s1_image\u001b[0;34m(date_ymd, region)\u001b[0m\n\u001b[1;32m     70\u001b[0m col \u001b[38;5;241m=\u001b[39m (ee\u001b[38;5;241m.\u001b[39mImageCollection(S1_COLLECTION)\n\u001b[1;32m     71\u001b[0m        \u001b[38;5;241m.\u001b[39mfilterBounds(region)\n\u001b[1;32m     72\u001b[0m        \u001b[38;5;241m.\u001b[39mfilterDate(start, end)\n\u001b[1;32m     73\u001b[0m        \u001b[38;5;241m.\u001b[39mfilter(ee\u001b[38;5;241m.\u001b[39mFilter\u001b[38;5;241m.\u001b[39minList(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstrumentMode\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlist\u001b[39m(S1_ACCEPT_MODES)))\n\u001b[1;32m     74\u001b[0m        \u001b[38;5;241m.\u001b[39mfilter(ee\u001b[38;5;241m.\u001b[39mFilter\u001b[38;5;241m.\u001b[39mlistContains(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransmitterReceiverPolarisation\u001b[39m\u001b[38;5;124m'\u001b[39m, pol)))\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[43mcol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetInfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     78\u001b[0m     last_err \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/ee/computedobject.py:107\u001b[0m, in \u001b[0;36mComputedObject.getInfo\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgetInfo\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Fetch and return information about this object.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m  Returns:\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m    The object can evaluate to anything.\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomputeValue\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/ee/data.py:1128\u001b[0m, in \u001b[0;36mcomputeValue\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1125\u001b[0m body \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpression\u001b[39m\u001b[38;5;124m'\u001b[39m: serializer\u001b[38;5;241m.\u001b[39mencode(obj, for_cloud_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)}\n\u001b[1;32m   1126\u001b[0m _maybe_populate_workload_tag(body)\n\u001b[0;32m-> 1128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_execute_cloud_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_get_cloud_projects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_get_projects_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprettyPrint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/ee/data.py:409\u001b[0m, in \u001b[0;36m_execute_cloud_call\u001b[0;34m(call, num_retries)\u001b[0m\n\u001b[1;32m    407\u001b[0m num_retries \u001b[38;5;241m=\u001b[39m _max_retries \u001b[38;5;28;01mif\u001b[39;00m num_retries \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m num_retries\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_retries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m googleapiclient\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mHttpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    411\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m _translate_cloud_exception(e)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/googleapiclient/_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m positional_parameters_enforcement \u001b[38;5;241m==\u001b[39m POSITIONAL_WARNING:\n\u001b[1;32m    129\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/googleapiclient/http.py:923\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbody))\n\u001b[1;32m    922\u001b[0m \u001b[38;5;66;03m# Handle retries for server-side errors.\u001b[39;00m\n\u001b[0;32m--> 923\u001b[0m resp, content \u001b[38;5;241m=\u001b[39m \u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrequest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muri\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_callbacks:\n\u001b[1;32m    936\u001b[0m     callback(resp)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/googleapiclient/http.py:187\u001b[0m, in \u001b[0;36m_retry_request\u001b[0;34m(http, num_retries, req_type, sleep, rand, uri, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     sleep_time \u001b[38;5;241m=\u001b[39m rand() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mretry_num\n\u001b[1;32m    177\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSleeping \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m seconds before retry \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m for \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, after \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    179\u001b[0m         sleep_time,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    185\u001b[0m         resp\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;28;01mif\u001b[39;00m resp \u001b[38;5;28;01melse\u001b[39;00m exception,\n\u001b[1;32m    186\u001b[0m     )\n\u001b[0;32m--> 187\u001b[0m     \u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43msleep_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ee\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------------- EE auth ----------------\n",
    "ee.Authenticate()   # comment this out if creds are already cached in your env\n",
    "ee.Initialize()\n",
    "\n",
    "# ---------------- Month folders ----------\n",
    "INPUT_MONTH_DIR  = r\"/mnt/cephfs-mount/chenchen/CygnssDataCsvLand/2021_02\"\n",
    "OUTPUT_MONTH_DIR = r\"/mnt/cephfs-mount/chenchen/water_body_fraction/2021_02_testmonth\"\n",
    "os.makedirs(OUTPUT_MONTH_DIR, exist_ok=True)\n",
    "\n",
    "# ---------------- Sampling ----------------\n",
    "SAMPLE_FRAC = 1   # 1% sample\n",
    "SAMPLE_SEED = 42     # keep this fixed for reproducibility\n",
    "\n",
    "# ---------------- Debug toggles ----------\n",
    "DEBUG_MODE     = False\n",
    "PRINT_PER_ROW  = False\n",
    "SKIP_IF_EXISTS = True  # set True to skip days that already have an output file\n",
    "\n",
    "# ---------------- S1 search settings -----\n",
    "S1_COLLECTION        = \"COPERNICUS/S1_GRD\"\n",
    "S1_ACCEPT_MODES      = (\"IW\", \"EW\")                 # accept both (skip WV)\n",
    "S1_POLS_PREFERENCE   = (\"VV\", \"VH\", \"HH\", \"HV\")     # try in this order\n",
    "S1_DAY_WINDOWS_TRY   = [0]                    # exact day, ±3d, ±6d\n",
    "S1_SCALE             = 10                           # meters\n",
    "\n",
    "# ---------------- Threshold + histogram ---\n",
    "VV_MIN_DB        = -30\n",
    "VV_MAX_DB        = 5\n",
    "VV_BUCKETS       = 256\n",
    "DEFAULT_THRESHOLD_DB = -18.5\n",
    "ALL_WATER_DB     = -19.0\n",
    "ALL_LAND_DB      = -15.0\n",
    "OTSU_CLAMP       = (-23.0, -15.0)\n",
    "\n",
    "# ---------------- Slope mask -------------\n",
    "SLOPE_DEG_MAX = 5.0\n",
    "_SLOPE_MASK = None  # lazy cache\n",
    "\n",
    "# ------------- Helpers -------------------\n",
    "_YMD_RE = re.compile(r\"(\\d{8})\\.csv$\")\n",
    "\n",
    "def date_from_csv_path(path):\n",
    "    \"\"\"Parse YYYYMMDD from filename like 20180801.csv -> '2018-08-01'.\"\"\"\n",
    "    base = os.path.basename(path)\n",
    "    m = _YMD_RE.match(base)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Cannot parse date from filename: {base}\")\n",
    "    ymd = m.group(1)\n",
    "    return f\"{ymd[:4]}-{ymd[4:6]}-{ymd[6:8]}\"\n",
    "\n",
    "def _load_s1_image(date_ymd, region):\n",
    "    \"\"\"\n",
    "    Try multiple windows, modes, polarizations. Return single-band image 'S1' or None.\n",
    "    \"\"\"\n",
    "    d0 = ee.Date(date_ymd)\n",
    "    last_err = None\n",
    "    for wnd in S1_DAY_WINDOWS_TRY:\n",
    "        start = d0.advance(-wnd, 'day')\n",
    "        end   = d0.advance(wnd + 1, 'day')\n",
    "        for pol in S1_POLS_PREFERENCE:\n",
    "            col = (ee.ImageCollection(S1_COLLECTION)\n",
    "                   .filterBounds(region)\n",
    "                   .filterDate(start, end)\n",
    "                   .filter(ee.Filter.inList('instrumentMode', list(S1_ACCEPT_MODES)))\n",
    "                   .filter(ee.Filter.listContains('transmitterReceiverPolarisation', pol)))\n",
    "            try:\n",
    "                n = col.size().getInfo()\n",
    "            except Exception as e:\n",
    "                last_err = e\n",
    "                n = 0\n",
    "            if n and n > 0:\n",
    "                img = col.mosaic().select(pol).rename('S1').set({\n",
    "                    'used_pol': pol, 'used_window_days': wnd\n",
    "                })\n",
    "                if DEBUG_MODE:\n",
    "                    tqdm.write(f\"[S1] {date_ymd}: {n} img(s), pol={pol}, ±{wnd}d\")\n",
    "                return img\n",
    "    if DEBUG_MODE:\n",
    "        # tqdm.write(f\"[S1] {date_ymd}: no images found\" + (f\" (last err: {last_err})\" if last_err else \"\"))\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def _build_slope_mask():\n",
    "    srtm = ee.Image(\"USGS/SRTMGL1_003\")\n",
    "    slope = ee.Terrain.slope(srtm)\n",
    "    return slope.lt(SLOPE_DEG_MAX).unmask(1)\n",
    "\n",
    "def _get_histogram(img_s1, region):\n",
    "    \"\"\"\n",
    "    Return {'bucketMeans','histogram'} for 'S1' band, or None.\n",
    "    Clamp image to [VV_MIN_DB, VV_MAX_DB].\n",
    "    \"\"\"\n",
    "    img_clamped = img_s1.clamp(VV_MIN_DB, VV_MAX_DB)\n",
    "    hist = (img_clamped.reduceRegion(\n",
    "        reducer=ee.Reducer.histogram(VV_BUCKETS),\n",
    "        geometry=region,\n",
    "        scale=S1_SCALE,\n",
    "        bestEffort=True,\n",
    "        maxPixels=1e13\n",
    "    ).get('S1'))\n",
    "    try:\n",
    "        info = hist.getInfo()\n",
    "    except Exception:\n",
    "        return None\n",
    "    if not info or \"bucketMeans\" not in info or \"histogram\" not in info:\n",
    "        return None\n",
    "    return info\n",
    "\n",
    "def _count_peaks(bucket_means, counts):\n",
    "    bm = np.asarray(bucket_means, dtype=float)\n",
    "    ct = np.asarray(counts, dtype=float)\n",
    "    if len(ct) < 3:\n",
    "        return 0, []\n",
    "    from numpy import convolve\n",
    "    kernel = np.array([1,2,3,2,1], dtype=float); kernel /= kernel.sum()\n",
    "    ct_s = convolve(ct, kernel, mode='same')\n",
    "    thresh = 0.05 * ct_s.max() if ct_s.max() > 0 else np.inf\n",
    "    peaks = []\n",
    "    for i in range(1, len(ct_s)-1):\n",
    "        if ct_s[i] > ct_s[i-1] and ct_s[i] > ct_s[i+1] and ct_s[i] >= thresh:\n",
    "            peaks.append(i)\n",
    "    return len(peaks), peaks\n",
    "\n",
    "def _otsu_threshold(bucket_means, counts):\n",
    "    bm = np.asarray(bucket_means, dtype=float)\n",
    "    ct = np.asarray(counts, dtype=float)\n",
    "    ct = np.maximum(ct, 0)\n",
    "    if ct.sum() == 0:\n",
    "        return None\n",
    "    prob = ct / ct.sum()\n",
    "    omega = np.cumsum(prob)\n",
    "    mu = np.cumsum(prob * bm)\n",
    "    mu_t = mu[-1]\n",
    "    sigma_b2 = (mu_t * omega - mu)**2 / (omega * (1 - omega) + 1e-12)\n",
    "    idx = np.nanargmax(sigma_b2)\n",
    "    thr = bm[idx]\n",
    "    return float(thr)\n",
    "\n",
    "def _choose_threshold_from_hist(hist):\n",
    "    bm = hist[\"bucketMeans\"]; ct = hist[\"histogram\"]\n",
    "    n_peaks, peak_idx = _count_peaks(bm, ct)\n",
    "    if n_peaks == 0:\n",
    "        return (\"default\", DEFAULT_THRESHOLD_DB)\n",
    "    if n_peaks == 1:\n",
    "        pk_val = bm[peak_idx[0]]\n",
    "        if pk_val <= ALL_WATER_DB: return (\"all_water\", DEFAULT_THRESHOLD_DB)\n",
    "        if pk_val >= ALL_LAND_DB:  return (\"all_land\",  DEFAULT_THRESHOLD_DB)\n",
    "        return (\"default\", DEFAULT_THRESHOLD_DB)\n",
    "    if n_peaks == 2:\n",
    "        thr = _otsu_threshold(bm, ct)\n",
    "        if thr is None or math.isnan(thr):\n",
    "            return (\"default\", DEFAULT_THRESHOLD_DB)\n",
    "        thr = max(OTSU_CLAMP[0], min(OTSU_CLAMP[1], thr))\n",
    "        return (\"otsu\", float(thr))\n",
    "    return (\"default\", DEFAULT_THRESHOLD_DB)\n",
    "\n",
    "# --------- ADVANCED water fraction (returns (frac, method, thr)) ----------\n",
    "def calculate_water_fraction(region, date_ee):\n",
    "    \"\"\"\n",
    "    Advanced method:\n",
    "      - robust S1 search (modes/pols/windows)\n",
    "      - histogram-based threshold (Otsu w/ clamps; fallbacks)\n",
    "      - slope mask (<=5°) before averaging water mask\n",
    "    Returns: (fraction in [0,1], method, thr_db) or (None, None, thr_db/maybe None).\n",
    "    \"\"\"\n",
    "    global _SLOPE_MASK\n",
    "    date_str = ee.Date(date_ee).format('YYYY-MM-dd').getInfo()\n",
    "\n",
    "    img_s1 = _load_s1_image(date_str, region)\n",
    "    if img_s1 is None:\n",
    "        return None, None, None\n",
    "\n",
    "    if _SLOPE_MASK is None:\n",
    "        _SLOPE_MASK = _build_slope_mask()\n",
    "\n",
    "    hist = _get_histogram(img_s1, region)\n",
    "    if hist is None:\n",
    "        return None, None, None\n",
    "\n",
    "    method, thr = _choose_threshold_from_hist(hist)\n",
    "\n",
    "    if method == \"all_water\":\n",
    "        water = ee.Image.constant(1).rename(\"water\")\n",
    "    elif method == \"all_land\":\n",
    "        water = ee.Image.constant(0).rename(\"water\")\n",
    "    else:\n",
    "        water = img_s1.lt(thr).rename(\"water\")\n",
    "\n",
    "    water_m = water.updateMask(_SLOPE_MASK)\n",
    "\n",
    "    frac = (water_m.reduceRegion(\n",
    "        reducer=ee.Reducer.mean(),\n",
    "        geometry=region,\n",
    "        scale=S1_SCALE,\n",
    "        bestEffort=True,\n",
    "        maxPixels=1e13\n",
    "    ).get(\"water\"))\n",
    "\n",
    "    try:\n",
    "        frac_val = frac.getInfo()\n",
    "    except Exception:\n",
    "        return None, method, thr\n",
    "\n",
    "    if frac_val is None:\n",
    "        return None, method, thr\n",
    "\n",
    "    frac_val = max(0.0, min(1.0, float(frac_val)))\n",
    "\n",
    "    if DEBUG_MODE and PRINT_PER_ROW:\n",
    "        thr_str = f\"{thr:.2f}\" if (thr is not None and np.isfinite(thr)) else \"NA\"\n",
    "        tqdm.write(f\"[DEBUG] {date_str} frac={frac_val:.4f} method={method} thr_db={thr_str}\")\n",
    "\n",
    "    return frac_val, method, thr\n",
    "\n",
    "def process_one_csv(input_csv_path, output_csv_path):\n",
    "    \"\"\"Process a single day CSV; write output CSV (only rows with results).\"\"\"\n",
    "    date_str = date_from_csv_path(input_csv_path)\n",
    "    date_ee  = ee.Date(date_str)\n",
    "    if DEBUG_MODE:\n",
    "        tqdm.write(f\"\\n[DAY] {date_str} | modes={S1_ACCEPT_MODES}, pols={S1_POLS_PREFERENCE}, windows={S1_DAY_WINDOWS_TRY}\")\n",
    "\n",
    "    # read\n",
    "    data = pd.read_csv(input_csv_path)\n",
    "    base_cols = data.columns.tolist()\n",
    "\n",
    "    # sample\n",
    "    total_rows = len(data)\n",
    "    if total_rows > 0 and 0 < SAMPLE_FRAC < 1:\n",
    "        n = max(1, int(round(SAMPLE_FRAC * total_rows)))\n",
    "        data = data.sample(n=n, random_state=SAMPLE_SEED, replace=False).sort_index()\n",
    "        #tqdm.write(f\"[SAMPLE] {os.path.basename(input_csv_path)} -> {len(data)}/{total_rows} rows (~{SAMPLE_FRAC*100:.2f}%)\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for _, row in tqdm(data.iterrows(), total=len(data), desc=f\"Rows {os.path.basename(input_csv_path)}\", leave=False):\n",
    "        try:\n",
    "            region_coords = [\n",
    "                [float(row['c1_lon']), float(row['c1_lat'])],\n",
    "                [float(row['c2_lon']), float(row['c2_lat'])],\n",
    "                [float(row['c3_lon']), float(row['c3_lat'])],\n",
    "                [float(row['c4_lon']), float(row['c4_lat'])],\n",
    "                [float(row['c1_lon']), float(row['c1_lat'])],  # close polygon\n",
    "            ]\n",
    "        except (KeyError, TypeError, ValueError):\n",
    "            continue\n",
    "\n",
    "        region = ee.Geometry.Polygon([region_coords], None, False)\n",
    "\n",
    "        frac, method, thr = calculate_water_fraction(region, date_ee)\n",
    "        if frac is not None and np.isfinite(frac):\n",
    "            if PRINT_PER_ROW:\n",
    "                thr_str = f\"{thr:.2f}\" if (thr is not None and np.isfinite(thr)) else \"NA\"\n",
    "                tqdm.write(f\"{date_str} frac={frac:.4f}, method={method}, thr_db={thr_str} @ {region_coords[0]}\")\n",
    "\n",
    "            out_row = row.to_dict()\n",
    "            out_row[\"water_fraction\"] = float(frac)\n",
    "            out_row[\"thr_method\"]     = method\n",
    "            out_row[\"thr_db\"]         = float(thr) if (thr is not None and np.isfinite(thr)) else np.nan\n",
    "            results.append(out_row)\n",
    "\n",
    "    # save (only rows with results). If none, write empty file with headers.\n",
    "    out_cols = base_cols + [\"water_fraction\", \"thr_method\", \"thr_db\"]\n",
    "    os.makedirs(os.path.dirname(output_csv_path), exist_ok=True)\n",
    "    pd.DataFrame(results, columns=out_cols).to_csv(output_csv_path, index=False)\n",
    "\n",
    "    if len(results) == 0:\n",
    "        tqdm.write(f\"No valid rows for {date_str}; wrote empty CSV: {output_csv_path}\")\n",
    "    else:\n",
    "        tqdm.write(f\"Saved {len(results)} rows -> {output_csv_path}\")\n",
    "\n",
    "def main():\n",
    "    # gather all yyyyMMdd.csv in the month folder\n",
    "    files = [f for f in os.listdir(INPUT_MONTH_DIR) if _YMD_RE.match(f)]\n",
    "    files.sort()  # chronological order\n",
    "    if not files:\n",
    "        print(f\"No daily CSVs found in {INPUT_MONTH_DIR}\")\n",
    "        return\n",
    "\n",
    "    #tqdm.write(f\"Daily CSVs in {os.path.basename(INPUT_MONTH_DIR)}: {len(files)} file(s)\")\n",
    "    for fname in (files):\n",
    "        in_path  = os.path.join(INPUT_MONTH_DIR, fname)\n",
    "        out_path = os.path.join(OUTPUT_MONTH_DIR, fname)\n",
    "\n",
    "        if SKIP_IF_EXISTS and os.path.exists(out_path):\n",
    "            tqdm.write(f\"[SKIP] {fname} exists\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            process_one_csv(in_path, out_path)\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"Failed to process {in_path}: {e}\")\n",
    "            # Optional: write an empty CSV with only headers if read succeeded earlier.\n",
    "            # Here we just continue.\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b1c4ed-3cba-4cab-9f00-15dad115dc57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
