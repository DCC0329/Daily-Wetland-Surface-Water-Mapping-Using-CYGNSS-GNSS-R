{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e762a779-b68c-4f55-8a1e-ba7f6ace3d5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2341 rows -> /mnt/cephfs-mount/chenchen/water_body_fraction/2021_05/20210501.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2541 rows -> /mnt/cephfs-mount/chenchen/water_body_fraction/2021_05/20210502.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2217 rows -> /mnt/cephfs-mount/chenchen/water_body_fraction/2021_05/20210503.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2121 rows -> /mnt/cephfs-mount/chenchen/water_body_fraction/2021_05/20210504.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2527 rows -> /mnt/cephfs-mount/chenchen/water_body_fraction/2021_05/20210505.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2461 rows -> /mnt/cephfs-mount/chenchen/water_body_fraction/2021_05/20210506.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2588 rows -> /mnt/cephfs-mount/chenchen/water_body_fraction/2021_05/20210507.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2139 rows -> /mnt/cephfs-mount/chenchen/water_body_fraction/2021_05/20210508.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2525 rows -> /mnt/cephfs-mount/chenchen/water_body_fraction/2021_05/20210509.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2347 rows -> /mnt/cephfs-mount/chenchen/water_body_fraction/2021_05/20210510.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2407 rows -> /mnt/cephfs-mount/chenchen/water_body_fraction/2021_05/20210511.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2454 rows -> /mnt/cephfs-mount/chenchen/water_body_fraction/2021_05/20210512.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2323 rows -> /mnt/cephfs-mount/chenchen/water_body_fraction/2021_05/20210513.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2372 rows -> /mnt/cephfs-mount/chenchen/water_body_fraction/2021_05/20210514.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2097 rows -> /mnt/cephfs-mount/chenchen/water_body_fraction/2021_05/20210515.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2108 rows -> /mnt/cephfs-mount/chenchen/water_body_fraction/2021_05/20210516.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2372 rows -> /mnt/cephfs-mount/chenchen/water_body_fraction/2021_05/20210517.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2466 rows -> /mnt/cephfs-mount/chenchen/water_body_fraction/2021_05/20210518.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rows 20210519.csv:   1%|▏                   | 96/14416 [01:16<2:04:22,  1.92it/s]"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ee\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------------- EE auth ----------------\n",
    "ee.Authenticate()   # comment this out if creds are already cached in your env\n",
    "ee.Initialize()\n",
    "\n",
    "# ---------------- Month folders ----------\n",
    "INPUT_MONTH_DIR  = r\"/mnt/cephfs-mount/chenchen/CygnssDataCsvLand/2021_05\"\n",
    "OUTPUT_MONTH_DIR = r\"/mnt/cephfs-mount/chenchen/water_body_fraction/2021_05\"\n",
    "os.makedirs(OUTPUT_MONTH_DIR, exist_ok=True)\n",
    "\n",
    "# ---------------- Sampling ----------------\n",
    "SAMPLE_FRAC = 0.01   # 1% sample\n",
    "SAMPLE_SEED = 42     # keep this fixed for reproducibility\n",
    "\n",
    "# ---------------- Debug toggles ----------\n",
    "DEBUG_MODE     = False\n",
    "PRINT_PER_ROW  = False\n",
    "SKIP_IF_EXISTS = True  # set True to skip days that already have an output file\n",
    "\n",
    "# ---------------- S1 search settings -----\n",
    "S1_COLLECTION        = \"COPERNICUS/S1_GRD\"\n",
    "S1_ACCEPT_MODES      = (\"IW\", \"EW\")                 # accept both (skip WV)\n",
    "S1_POLS_PREFERENCE   = (\"VV\", \"VH\", \"HH\", \"HV\")     # try in this order\n",
    "S1_DAY_WINDOWS_TRY   = [0]                    # exact day, ±3d, ±6d\n",
    "S1_SCALE             = 10                           # meters\n",
    "\n",
    "# ---------------- Threshold + histogram ---\n",
    "VV_MIN_DB        = -30\n",
    "VV_MAX_DB        = 5\n",
    "VV_BUCKETS       = 256\n",
    "DEFAULT_THRESHOLD_DB = -18.5\n",
    "ALL_WATER_DB     = -19.0\n",
    "ALL_LAND_DB      = -15.0\n",
    "OTSU_CLAMP       = (-23.0, -15.0)\n",
    "\n",
    "# ---------------- Slope mask -------------\n",
    "SLOPE_DEG_MAX = 5.0\n",
    "_SLOPE_MASK = None  # lazy cache\n",
    "\n",
    "# ------------- Helpers -------------------\n",
    "_YMD_RE = re.compile(r\"(\\d{8})\\.csv$\")\n",
    "\n",
    "def date_from_csv_path(path):\n",
    "    \"\"\"Parse YYYYMMDD from filename like 20180801.csv -> '2018-08-01'.\"\"\"\n",
    "    base = os.path.basename(path)\n",
    "    m = _YMD_RE.match(base)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Cannot parse date from filename: {base}\")\n",
    "    ymd = m.group(1)\n",
    "    return f\"{ymd[:4]}-{ymd[4:6]}-{ymd[6:8]}\"\n",
    "\n",
    "def _load_s1_image(date_ymd, region):\n",
    "    \"\"\"\n",
    "    Try multiple windows, modes, polarizations. Return single-band image 'S1' or None.\n",
    "    \"\"\"\n",
    "    d0 = ee.Date(date_ymd)\n",
    "    last_err = None\n",
    "    for wnd in S1_DAY_WINDOWS_TRY:\n",
    "        start = d0.advance(-wnd, 'day')\n",
    "        end   = d0.advance(wnd + 1, 'day')\n",
    "        for pol in S1_POLS_PREFERENCE:\n",
    "            col = (ee.ImageCollection(S1_COLLECTION)\n",
    "                   .filterBounds(region)\n",
    "                   .filterDate(start, end)\n",
    "                   .filter(ee.Filter.inList('instrumentMode', list(S1_ACCEPT_MODES)))\n",
    "                   .filter(ee.Filter.listContains('transmitterReceiverPolarisation', pol)))\n",
    "            try:\n",
    "                n = col.size().getInfo()\n",
    "            except Exception as e:\n",
    "                last_err = e\n",
    "                n = 0\n",
    "            if n and n > 0:\n",
    "                img = col.mosaic().select(pol).rename('S1').set({\n",
    "                    'used_pol': pol, 'used_window_days': wnd\n",
    "                })\n",
    "                if DEBUG_MODE:\n",
    "                    tqdm.write(f\"[S1] {date_ymd}: {n} img(s), pol={pol}, ±{wnd}d\")\n",
    "                return img\n",
    "    if DEBUG_MODE:\n",
    "        # tqdm.write(f\"[S1] {date_ymd}: no images found\" + (f\" (last err: {last_err})\" if last_err else \"\"))\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def _build_slope_mask():\n",
    "    srtm = ee.Image(\"USGS/SRTMGL1_003\")\n",
    "    slope = ee.Terrain.slope(srtm)\n",
    "    return slope.lt(SLOPE_DEG_MAX).unmask(1)\n",
    "\n",
    "def _get_histogram(img_s1, region):\n",
    "    \"\"\"\n",
    "    Return {'bucketMeans','histogram'} for 'S1' band, or None.\n",
    "    Clamp image to [VV_MIN_DB, VV_MAX_DB].\n",
    "    \"\"\"\n",
    "    img_clamped = img_s1.clamp(VV_MIN_DB, VV_MAX_DB)\n",
    "    hist = (img_clamped.reduceRegion(\n",
    "        reducer=ee.Reducer.histogram(VV_BUCKETS),\n",
    "        geometry=region,\n",
    "        scale=S1_SCALE,\n",
    "        bestEffort=True,\n",
    "        maxPixels=1e13\n",
    "    ).get('S1'))\n",
    "    try:\n",
    "        info = hist.getInfo()\n",
    "    except Exception:\n",
    "        return None\n",
    "    if not info or \"bucketMeans\" not in info or \"histogram\" not in info:\n",
    "        return None\n",
    "    return info\n",
    "\n",
    "def _count_peaks(bucket_means, counts):\n",
    "    bm = np.asarray(bucket_means, dtype=float)\n",
    "    ct = np.asarray(counts, dtype=float)\n",
    "    if len(ct) < 3:\n",
    "        return 0, []\n",
    "    from numpy import convolve\n",
    "    kernel = np.array([1,2,3,2,1], dtype=float); kernel /= kernel.sum()\n",
    "    ct_s = convolve(ct, kernel, mode='same')\n",
    "    thresh = 0.05 * ct_s.max() if ct_s.max() > 0 else np.inf\n",
    "    peaks = []\n",
    "    for i in range(1, len(ct_s)-1):\n",
    "        if ct_s[i] > ct_s[i-1] and ct_s[i] > ct_s[i+1] and ct_s[i] >= thresh:\n",
    "            peaks.append(i)\n",
    "    return len(peaks), peaks\n",
    "\n",
    "def _otsu_threshold(bucket_means, counts):\n",
    "    bm = np.asarray(bucket_means, dtype=float)\n",
    "    ct = np.asarray(counts, dtype=float)\n",
    "    ct = np.maximum(ct, 0)\n",
    "    if ct.sum() == 0:\n",
    "        return None\n",
    "    prob = ct / ct.sum()\n",
    "    omega = np.cumsum(prob)\n",
    "    mu = np.cumsum(prob * bm)\n",
    "    mu_t = mu[-1]\n",
    "    sigma_b2 = (mu_t * omega - mu)**2 / (omega * (1 - omega) + 1e-12)\n",
    "    idx = np.nanargmax(sigma_b2)\n",
    "    thr = bm[idx]\n",
    "    return float(thr)\n",
    "\n",
    "def _choose_threshold_from_hist(hist):\n",
    "    bm = hist[\"bucketMeans\"]; ct = hist[\"histogram\"]\n",
    "    n_peaks, peak_idx = _count_peaks(bm, ct)\n",
    "    if n_peaks == 0:\n",
    "        return (\"default\", DEFAULT_THRESHOLD_DB)\n",
    "    if n_peaks == 1:\n",
    "        pk_val = bm[peak_idx[0]]\n",
    "        if pk_val <= ALL_WATER_DB: return (\"all_water\", DEFAULT_THRESHOLD_DB)\n",
    "        if pk_val >= ALL_LAND_DB:  return (\"all_land\",  DEFAULT_THRESHOLD_DB)\n",
    "        return (\"default\", DEFAULT_THRESHOLD_DB)\n",
    "    if n_peaks == 2:\n",
    "        thr = _otsu_threshold(bm, ct)\n",
    "        if thr is None or math.isnan(thr):\n",
    "            return (\"default\", DEFAULT_THRESHOLD_DB)\n",
    "        thr = max(OTSU_CLAMP[0], min(OTSU_CLAMP[1], thr))\n",
    "        return (\"otsu\", float(thr))\n",
    "    return (\"default\", DEFAULT_THRESHOLD_DB)\n",
    "\n",
    "# --------- ADVANCED water fraction (returns (frac, method, thr)) ----------\n",
    "def calculate_water_fraction(region, date_ee):\n",
    "    \"\"\"\n",
    "    Advanced method:\n",
    "      - robust S1 search (modes/pols/windows)\n",
    "      - histogram-based threshold (Otsu w/ clamps; fallbacks)\n",
    "      - slope mask (<=5°) before averaging water mask\n",
    "    Returns: (fraction in [0,1], method, thr_db) or (None, None, thr_db/maybe None).\n",
    "    \"\"\"\n",
    "    global _SLOPE_MASK\n",
    "    date_str = ee.Date(date_ee).format('YYYY-MM-dd').getInfo()\n",
    "\n",
    "    img_s1 = _load_s1_image(date_str, region)\n",
    "    if img_s1 is None:\n",
    "        return None, None, None\n",
    "\n",
    "    if _SLOPE_MASK is None:\n",
    "        _SLOPE_MASK = _build_slope_mask()\n",
    "\n",
    "    hist = _get_histogram(img_s1, region)\n",
    "    if hist is None:\n",
    "        return None, None, None\n",
    "\n",
    "    method, thr = _choose_threshold_from_hist(hist)\n",
    "\n",
    "    if method == \"all_water\":\n",
    "        water = ee.Image.constant(1).rename(\"water\")\n",
    "    elif method == \"all_land\":\n",
    "        water = ee.Image.constant(0).rename(\"water\")\n",
    "    else:\n",
    "        water = img_s1.lt(thr).rename(\"water\")\n",
    "\n",
    "    water_m = water.updateMask(_SLOPE_MASK)\n",
    "\n",
    "    frac = (water_m.reduceRegion(\n",
    "        reducer=ee.Reducer.mean(),\n",
    "        geometry=region,\n",
    "        scale=S1_SCALE,\n",
    "        bestEffort=True,\n",
    "        maxPixels=1e13\n",
    "    ).get(\"water\"))\n",
    "\n",
    "    try:\n",
    "        frac_val = frac.getInfo()\n",
    "    except Exception:\n",
    "        return None, method, thr\n",
    "\n",
    "    if frac_val is None:\n",
    "        return None, method, thr\n",
    "\n",
    "    frac_val = max(0.0, min(1.0, float(frac_val)))\n",
    "\n",
    "    if DEBUG_MODE and PRINT_PER_ROW:\n",
    "        thr_str = f\"{thr:.2f}\" if (thr is not None and np.isfinite(thr)) else \"NA\"\n",
    "        tqdm.write(f\"[DEBUG] {date_str} frac={frac_val:.4f} method={method} thr_db={thr_str}\")\n",
    "\n",
    "    return frac_val, method, thr\n",
    "\n",
    "def process_one_csv(input_csv_path, output_csv_path):\n",
    "    \"\"\"Process a single day CSV; write output CSV (only rows with results).\"\"\"\n",
    "    date_str = date_from_csv_path(input_csv_path)\n",
    "    date_ee  = ee.Date(date_str)\n",
    "    if DEBUG_MODE:\n",
    "        tqdm.write(f\"\\n[DAY] {date_str} | modes={S1_ACCEPT_MODES}, pols={S1_POLS_PREFERENCE}, windows={S1_DAY_WINDOWS_TRY}\")\n",
    "\n",
    "    # read\n",
    "    data = pd.read_csv(input_csv_path)\n",
    "    base_cols = data.columns.tolist()\n",
    "\n",
    "    # sample\n",
    "    total_rows = len(data)\n",
    "    if total_rows > 0 and 0 < SAMPLE_FRAC < 1:\n",
    "        n = max(1, int(round(SAMPLE_FRAC * total_rows)))\n",
    "        data = data.sample(n=n, random_state=SAMPLE_SEED, replace=False).sort_index()\n",
    "        #tqdm.write(f\"[SAMPLE] {os.path.basename(input_csv_path)} -> {len(data)}/{total_rows} rows (~{SAMPLE_FRAC*100:.2f}%)\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for _, row in tqdm(data.iterrows(), total=len(data), desc=f\"Rows {os.path.basename(input_csv_path)}\", leave=False):\n",
    "        try:\n",
    "            region_coords = [\n",
    "                [float(row['c1_lon']), float(row['c1_lat'])],\n",
    "                [float(row['c2_lon']), float(row['c2_lat'])],\n",
    "                [float(row['c3_lon']), float(row['c3_lat'])],\n",
    "                [float(row['c4_lon']), float(row['c4_lat'])],\n",
    "                [float(row['c1_lon']), float(row['c1_lat'])],  # close polygon\n",
    "            ]\n",
    "        except (KeyError, TypeError, ValueError):\n",
    "            continue\n",
    "\n",
    "        region = ee.Geometry.Polygon([region_coords], None, False)\n",
    "\n",
    "        frac, method, thr = calculate_water_fraction(region, date_ee)\n",
    "        if frac is not None and np.isfinite(frac):\n",
    "            if PRINT_PER_ROW:\n",
    "                thr_str = f\"{thr:.2f}\" if (thr is not None and np.isfinite(thr)) else \"NA\"\n",
    "                tqdm.write(f\"{date_str} frac={frac:.4f}, method={method}, thr_db={thr_str} @ {region_coords[0]}\")\n",
    "\n",
    "            out_row = row.to_dict()\n",
    "            out_row[\"water_fraction\"] = float(frac)\n",
    "            out_row[\"thr_method\"]     = method\n",
    "            out_row[\"thr_db\"]         = float(thr) if (thr is not None and np.isfinite(thr)) else np.nan\n",
    "            results.append(out_row)\n",
    "\n",
    "    # save (only rows with results). If none, write empty file with headers.\n",
    "    out_cols = base_cols + [\"water_fraction\", \"thr_method\", \"thr_db\"]\n",
    "    os.makedirs(os.path.dirname(output_csv_path), exist_ok=True)\n",
    "    pd.DataFrame(results, columns=out_cols).to_csv(output_csv_path, index=False)\n",
    "\n",
    "    if len(results) == 0:\n",
    "        tqdm.write(f\"No valid rows for {date_str}; wrote empty CSV: {output_csv_path}\")\n",
    "    else:\n",
    "        tqdm.write(f\"Saved {len(results)} rows -> {output_csv_path}\")\n",
    "\n",
    "def main():\n",
    "    # gather all yyyyMMdd.csv in the month folder\n",
    "    files = [f for f in os.listdir(INPUT_MONTH_DIR) if _YMD_RE.match(f)]\n",
    "    files.sort()  # chronological order\n",
    "    if not files:\n",
    "        print(f\"No daily CSVs found in {INPUT_MONTH_DIR}\")\n",
    "        return\n",
    "\n",
    "    #tqdm.write(f\"Daily CSVs in {os.path.basename(INPUT_MONTH_DIR)}: {len(files)} file(s)\")\n",
    "    for fname in (files):\n",
    "        in_path  = os.path.join(INPUT_MONTH_DIR, fname)\n",
    "        out_path = os.path.join(OUTPUT_MONTH_DIR, fname)\n",
    "\n",
    "        if SKIP_IF_EXISTS and os.path.exists(out_path):\n",
    "            tqdm.write(f\"[SKIP] {fname} exists\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            process_one_csv(in_path, out_path)\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"Failed to process {in_path}: {e}\")\n",
    "            # Optional: write an empty CSV with only headers if read succeeded earlier.\n",
    "            # Here we just continue.\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b551a4f6-3f33-4092-ae70-7cd7f0941669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdf8688-7c58-4033-b19b-ffa93d1ededd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
